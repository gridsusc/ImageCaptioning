{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import glob\n",
    "import h5py\n",
    "import string\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import json\n",
    "\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('popular')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "with open(\"./caption_datasets/dataset_flickr8k.json\", \"r\") as f:\n",
    "    cap_data = json.load(f)\n",
    "\n",
    "train, test, val = set(), set(), set()\n",
    "\n",
    "file_split = map(lambda a: (a['filename'], a['split']), cap_data['images'])\n",
    "\n",
    "for file, split in file_split:\n",
    "\n",
    "    if split == 'train':\n",
    "        train.add(file)\n",
    "    if split == 'test':\n",
    "        test.add(file)\n",
    "    if split == 'val':\n",
    "        val.add(file)\n",
    "\n",
    "print(len(train), len(test), len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createHDF5(paths, split):\n",
    "\n",
    "    for path in paths:\n",
    "        img = Image.open(path)\n",
    "        \n",
    "        tensor_img = transforms.Compose([\n",
    "            transforms.PILToTensor(),\n",
    "            transforms.Resize([256,256]),\n",
    "            transforms.ConvertImageDtype(torch.float),\n",
    "        ])\n",
    "\n",
    "        image_tensor_list.append(tensor_img(img))\n",
    "\n",
    "    with h5py.File(\"./dataset/image_dataset_\"+split+\".hdf5\", \"w\") as f:\n",
    "        f.create_dataset(\"default\", data=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8091, 3, 256, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imageDir = \"./Images/\"\n",
    "\n",
    "img_paths = glob.glob(imageDir + \"*\")\n",
    "\n",
    "image_tensor_list = []\n",
    "\n",
    "for path in img_paths:\n",
    "\n",
    "    img = Image.open(path)\n",
    "    # img.show()\n",
    "    \n",
    "    tensor_img = transforms.Compose([\n",
    "        transforms.PILToTensor(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.ConvertImageDtype(torch.float),\n",
    "    ])\n",
    "\n",
    "    image_tensor_list.append(tensor_img(img))\n",
    "\n",
    "    # back_to_image = transforms.ToPILImage()\n",
    "    # back_to_image(image_tensor_list[0]).show()\n",
    "\n",
    "\n",
    "images = torch.stack(image_tensor_list)\n",
    "\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"./dataset/imageDataset.hdf5\", \"w\") as f:\n",
    "    dset = f.create_dataset(\"default\", data=images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_path = \"./captions.txt\"\n",
    "\n",
    "img_caption_list = pd.read_csv(captions_path)\n",
    "captions = img_caption_list['caption']\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "captions = captions.apply(lambda row : tokenizer.tokenize(row.lower()))\n",
    "\n",
    "captions.to_json(\"./dataset/captions.json\",orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "caption_length = captions.apply(lambda row : len(row))\n",
    "caption_length.to_json(\"./dataset/caption_lengths.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = {}\n",
    "\n",
    "for cap in captions:\n",
    "    for word in cap:\n",
    "        wordCount[word] = wordCount.get(word, 0) + 1\n",
    "\n",
    "sortedWords = sorted(wordCount.items(), key=lambda a: -a[1])\n",
    "\n",
    "k = 5000\n",
    "word_to_index = {word[0]: i for i, word in enumerate(sortedWords[:k])}\n",
    "\n",
    "\n",
    "tokens = {\"<sos>\": k+1, \"<eos>\": k+2, \"<pad>\": k+3, \"<unk>\": k+4}\n",
    "\n",
    "word_to_index.update(tokens)\n",
    "\n",
    "index_to_word = {v: k for k, v in word_to_index.items()}\n",
    "\n",
    "with open(\"./dataset/word_to_index_map.json\", \"w\") as f:\n",
    "    json.dump(word_to_index, f)\n",
    "\n",
    "with open(\"./dataset/index_to_word.json\", \"w\") as f:\n",
    "    json.dump(index_to_word, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseCaptionLen = max(map(len, captions)) + 2\n",
    "baseCaptionLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padEachCaption(caption, maxlen):\n",
    "\n",
    "    padlist = [\"<pad>\"]*(maxlen-2-len(caption))\n",
    "    return [\"<sos>\"]+caption+[\"<eos>\"]+padlist\n",
    "\n",
    "padded_captions = list(map(lambda a: padEachCaption(a, baseCaptionLen), captions))\n",
    "\n",
    "\n",
    "with open(\"./dataset/tokenized_captions.json\", \"w\") as f:\n",
    "    json.dump(padded_captions, f)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "274112944ad21e81c571316bb56183df52202ab27ed91e8ff04369e158d07c73"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
